{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541eb2f1",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b84e441b",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: langchain in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (1.0.4)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (1.0.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (2.12.4)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (1.0.2)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (1.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langchain-core->-r requirements.txt (line 3)) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langchain-core->-r requirements.txt (line 3)) (0.4.41)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langchain-core->-r requirements.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langchain-core->-r requirements.txt (line 3)) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langchain-core->-r requirements.txt (line 3)) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langchain-core->-r requirements.txt (line 3)) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from pydantic->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from pydantic->-r requirements.txt (line 4)) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from pydantic->-r requirements.txt (line 4)) (0.4.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core->-r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 2)) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 2)) (1.0.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 2)) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 2)) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 2)) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 2)) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 3)) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 3)) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 2)) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 2)) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 2)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langchain-openai->-r requirements.txt (line 5)) (2.7.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from langchain-openai->-r requirements.txt (line 5)) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai->-r requirements.txt (line 5)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai->-r requirements.txt (line 5)) (0.11.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai->-r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai->-r requirements.txt (line 5)) (2025.11.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 3)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 3)) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai->-r requirements.txt (line 5)) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.3.3-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-2.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7a09c35",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n   I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ce7c",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e92dff22",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.chains import LLMChain\n",
    "llm_model = \"gpt-4o-mini\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7abc20b",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebrady\\AppData\\Local\\Temp\\ipykernel_12440\\1305865249.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use `RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad44d1fb",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Choosing a name for a company that specializes in fishing boots can be crucial for branding and market appeal. Here are some ideas that convey purpose, durability, and the spirit of fishing:\\n\\n1. **Angler's Gear**\\n2. **Hook & Sole**\\n3. **Catch & Comfort Boots**\\n4. **Reel Footwear**\\n5. **TideWalker Boots**\\n6. **FishFit Footwear**\\n7. **LureBoots**\\n8. **StreamStep Boots**\\n9. **Baited Boots**\\n10. **AquaTread**\\n\\nConsider picking a name that resonates with your target audience and reflects the quality and features of your products. Additionally, check for domain availability if you plan to create a website!\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Fishing Boots\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b03469",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "febee243",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_classic.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f31aa8a",
   "metadata": {
    "height": 183,
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f5d5b76",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c1eb2c4",
   "metadata": {
    "height": 79,
    "tags": []
   },
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78458efe",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mChoosing a name for a company that makes fishing boots can be both fun and strategic. Here are some suggestions that evoke the spirit of fishing while also suggesting durability and comfort:\n",
      "\n",
      "1. **Angler's Edge**\n",
      "2. **Catch & Comfort**\n",
      "3. **ReelStep Boots**\n",
      "4. **TideRider**\n",
      "5. **FishFoot Gear**\n",
      "6. **Hook & Sole**\n",
      "7. **Aquatic Trek**\n",
      "8. **WaterWalker Boots**\n",
      "9. **CastAway Footwear**\n",
      "10. **FinFootwear**\n",
      "\n",
      "Make sure to check for domain availability and trademarks when selecting a name!\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mIntroducing durable and comfortable fishing boots, designed for avid anglers. Our brand names evoke adventure, quality, and aquatic enjoyment.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Introducing durable and comfortable fishing boots, designed for avid anglers. Our brand names evoke adventure, quality, and aquatic enjoyment.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ce18c",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c129ef6",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_classic.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "016187ac",
   "metadata": {
    "height": 217,
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fb0730e",
   "metadata": {
    "height": 181,
    "tags": []
   },
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6accf92d",
   "metadata": {
    "height": 181,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7a46121",
   "metadata": {
    "height": 232,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89603117",
   "metadata": {
    "height": 164,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51b04f45",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': \"This mattress had a small hole in the top of it (took forever to find where it was), and the patches that they provide did not work, maybe because it's the top of the mattress where it's kind of like fabric and a patch won't stick. Maybe I got unlucky with a defective mattress, but where's quality assurance for this company? That flat out should not happen. Emphasis on flat. Cause that's what the mattress was. Seriously horrible experience, ruined my friend's stay with me. Then they make you ship it back instead of just providing a refund, which is also super annoying to pack up an air mattress and take it to the UPS store. This company is the worst, and this mattress is the worst.\",\n",
       " 'English_Review': 'This mattress had a small hole in the top (it took forever to find where it was), and the patches they provided did not work, maybe because it\\'s the top of the mattress where it\\'s kind of like fabric and a patch won\\'t stick. Maybe I got unlucky with a defective mattress, but where\\'s the quality assurance for this company? That should not happen. Emphasis on \"flat.\" Because that\\'s what the mattress was. Seriously horrible experience; it ruined my friend\\'s stay with me. Then they make you ship it back instead of just providing a refund, which is super annoying to pack up an air mattress and take it to the UPS store. This company is the worst, and this mattress is the worst.',\n",
       " 'summary': 'The reviewer had a terrible experience with a defective mattress that arrived with a hole, ineffective patches, and a frustrating return process, leading them to view the company and product very negatively.',\n",
       " 'followup_message': 'Response: Thank you for taking the time to share your feedback. We are truly sorry to hear about your experience with the defective mattress and the challenges you faced during the return process. This is not the standard we strive for, and we understand how frustrating it can be. We would like to resolve this issue for you as quickly as possible. Please reach out to our customer service team at your earliest convenience so we can assist you further and ensure your concerns are addressed. Your satisfaction is important to us, and we appreciate the chance to make this right.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[2]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041ea4c",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ade83f4f",
   "metadata": {
    "height": 793,
    "tags": []
   },
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f590e9f",
   "metadata": {
    "height": 402,
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31b06fc8",
   "metadata": {
    "height": 79,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_classic.chains.router import MultiPromptChain\n",
    "from langchain_classic.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3f50bcc",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8eefec24",
   "metadata": {
    "height": 215,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f98018a",
   "metadata": {
    "height": 62,
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11b2e2ba",
   "metadata": {
    "height": 521,
    "tags": []
   },
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ \"DEFAULT\" or name of the prompt to use in {destinations}\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: The value of “destination” MUST match one of \\\n",
    "the candidate prompts listed below.\\\n",
    "If “destination” does not fit any of the specified prompts, set it to “DEFAULT.”\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1387109d",
   "metadata": {
    "height": 198,
    "tags": []
   },
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fb7d560",
   "metadata": {
    "height": 96,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebrady\\AppData\\Local\\Temp\\ipykernel_12440\\3038952769.py:1: LangChainDeprecationWarning: Please see migration guide here for recommended implementation: https://python.langchain.com/docs/versions/migrating_chains/multi_prompt_chain/\n",
      "  chain = MultiPromptChain(router_chain=router_chain,\n"
     ]
    }
   ],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d86b2131",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Black body radiation refers to the electromagnetic radiation emitted by an idealized object known as a \"black body.\" A black body is a perfect absorber of all incident radiation, meaning it absorbs all wavelengths of light and does not reflect any. When heated, a black body emits radiation in a characteristic spectrum that depends solely on its temperature.\\n\\nThe key features of black body radiation include:\\n\\n1. **Temperature Dependence**: The intensity and wavelength distribution of the emitted radiation depend on the temperature of the black body. As the temperature increases, the peak wavelength of the emitted radiation shifts to shorter wavelengths (this is described by Wien\\'s displacement law).\\n\\n2. **Planck\\'s Law**: The spectral distribution of black body radiation is described by Planck\\'s law, which quantifies the intensity of radiation emitted at different wavelengths for a given temperature.\\n\\n3. **Stefan-Boltzmann Law**: The total energy emitted per unit surface area of a black body is proportional to the fourth power of its absolute temperature (T^4). This is known as the Stefan-Boltzmann law.\\n\\nBlack body radiation played a crucial role in the development of quantum mechanics, particularly through Max Planck\\'s introduction of quantized energy levels to explain the observed spectrum, which resolved the ultraviolet catastrophe predicted by classical physics.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b717379",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'what is 2 + 2'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To solve the problem \\\\(2 + 2\\\\), we can break it down into its component parts:\\n\\n1. Identify the numbers involved: We have the numbers 2 and 2.\\n2. Understand the operation: The operation we are performing is addition.\\n\\nNow, we can add the two numbers together:\\n\\n\\\\[\\n2 + 2 = 4\\n\\\\]\\n\\nSo, the answer to the question \\\\(2 + 2\\\\) is \\\\(4\\\\).'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29e5be01",
   "metadata": {
    "height": 45,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'Why does every cell in our body contain DNA?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Every cell in our body contains DNA because DNA serves as the genetic blueprint for the organism. Here are several key reasons why this is the case:\\n\\n1. **Genetic Information**: DNA contains the instructions needed for the development, functioning, growth, and reproduction of all living organisms. It encodes the information necessary to produce proteins, which perform a vast array of functions in the body.\\n\\n2. **Cellular Function**: Each cell type in the body has specific functions, and the DNA in each cell contains the genes that are necessary for that cell's role. For example, muscle cells have genes that help them contract, while nerve cells have genes that support their ability to transmit signals.\\n\\n3. **Development and Differentiation**: During the development of an organism, all cells originate from a single fertilized egg, which contains DNA. As cells divide and differentiate into various types, they retain a complete copy of the original DNA, ensuring that they have the full set of instructions needed for their specific functions.\\n\\n4. **Repair and Maintenance**: DNA is crucial for the repair and maintenance of cells. When cells are damaged or when they divide, they need to replicate their DNA accurately to ensure that each new cell has the same genetic information as the original.\\n\\n5. **Inheritance**: DNA is passed from parents to offspring, ensuring that genetic traits are inherited. This continuity of genetic information is essential for the survival and evolution of species.\\n\\n6. **Regulation of Gene Expression**: While all cells contain the same DNA, not all genes are active in every cell. The regulation of gene expression allows cells to respond to their environment and perform specialized functions while still retaining the complete genetic information.\\n\\nIn summary, the presence of DNA in every cell is fundamental to the biological processes that sustain life, allowing for growth, development, and the maintenance of the organism.\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
