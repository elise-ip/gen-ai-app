{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3125b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac417803",
   "metadata": {},
   "source": [
    "### Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9257248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\ebrady\\personalprojects\\gen-ai-app\\.venv\\lib\\site-packages (6.2.0)\n",
      "Collecting yt_dlp\n",
      "  Downloading yt_dlp-2025.10.22-py3-none-any.whl.metadata (176 kB)\n",
      "Downloading yt_dlp-2025.10.22-py3-none-any.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.8/3.2 MB 8.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.1/3.2 MB 12.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.2/3.2 MB 8.0 MB/s  0:00:00\n",
      "Installing collected packages: yt_dlp\n",
      "Successfully installed yt_dlp-2025.10.22\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pypdf yt_dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f9260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is just spend a little time going over the logistics \n",
      "of the class, and then we'll start to talk a bit about machine learning.  \n",
      "By way of introduction, my name's Andrew Ng and I'll be instructor for this class. And so \n",
      "I personally work in machine learning, and I've worked on it for about 15 years now, and \n",
      "I actually think that machine learning is the \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'producer': 'Acrobat Distiller 8.1.0 (Windows)',\n",
       " 'creator': 'PScript5.dll Version 5.2.2',\n",
       " 'creationdate': '2008-07-11T11:25:23-07:00',\n",
       " 'author': '',\n",
       " 'moddate': '2008-07-11T11:25:23-07:00',\n",
       " 'title': '',\n",
       " 'source': 'MachineLearning-Lecture01.pdf',\n",
       " 'total_pages': 22,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_classic.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "\n",
    "len(pages)\n",
    "\n",
    "page=pages[0]\n",
    "print(page.page_content[0:500])\n",
    "page.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04656642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=jGwO_UgTS7I\n",
      "[youtube] jGwO_UgTS7I: Downloading webpage\n",
      "[youtube] jGwO_UgTS7I: Downloading android sdkless player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading tv client config\n",
      "[youtube] jGwO_UgTS7I: Downloading player 7f3b257d-main\n",
      "[youtube] jGwO_UgTS7I: Downloading tv player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading web safari player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/7f3b257d/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] jGwO_UgTS7I: nsig extraction failed: Some formats may be missing\n",
      "         n = Vu5thTOtenuIm17Q5 ; player = https://www.youtube.com/s/player/7f3b257d/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] jGwO_UgTS7I: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] jGwO_UgTS7I: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] jGwO_UgTS7I: Downloading m3u8 information\n",
      "[info] jGwO_UgTS7I: Downloading 1 format(s): 140\n",
      "[download] Sleeping 4.00 seconds as required by the site...\n",
      "[download] Destination: docs\\youtube\\Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a\n",
      "[download] 100% of   69.76MiB in 00:00:04 at 15.04MiB/s    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: jGwO_UgTS7I: writing DASH m4a. Only some players support this container. Install ffmpeg to fix this automatically\n",
      "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\n"
     ]
    },
    {
     "ename": "DownloadError",
     "evalue": "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPostProcessingError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3563\u001b[39m, in \u001b[36mYoutubeDL.process_info\u001b[39m\u001b[34m(self, info_dict)\u001b[39m\n\u001b[32m   3562\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3563\u001b[39m     replace_info_dict(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpost_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles_to_move\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   3564\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m PostProcessingError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3749\u001b[39m, in \u001b[36mYoutubeDL.post_process\u001b[39m\u001b[34m(self, filename, info, files_to_move)\u001b[39m\n\u001b[32m   3748\u001b[39m info[\u001b[33m'\u001b[39m\u001b[33m__files_to_move\u001b[39m\u001b[33m'\u001b[39m] = files_to_move \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m-> \u001b[39m\u001b[32m3749\u001b[39m info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_all_pps\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost_process\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_pps\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m__postprocessors\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3750\u001b[39m info = \u001b[38;5;28mself\u001b[39m.run_pp(MoveFilesAfterDownloadPP(\u001b[38;5;28mself\u001b[39m), info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3731\u001b[39m, in \u001b[36mYoutubeDL.run_all_pps\u001b[39m\u001b[34m(self, key, info, additional_pps)\u001b[39m\n\u001b[32m   3730\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pp \u001b[38;5;129;01min\u001b[39;00m (additional_pps \u001b[38;5;129;01mor\u001b[39;00m []) + \u001b[38;5;28mself\u001b[39m._pps[key]:\n\u001b[32m-> \u001b[39m\u001b[32m3731\u001b[39m     info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_pp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3732\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m info\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3709\u001b[39m, in \u001b[36mYoutubeDL.run_pp\u001b[39m\u001b[34m(self, pp, infodict)\u001b[39m\n\u001b[32m   3708\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3709\u001b[39m     files_to_delete, infodict = \u001b[43mpp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfodict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3710\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m PostProcessingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3711\u001b[39m     \u001b[38;5;66;03m# Must be True and not 'only_download'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\postprocessor\\common.py:23\u001b[39m, in \u001b[36mPostProcessorMetaClass.run_wrapper.<locals>.run\u001b[39m\u001b[34m(self, info, *args, **kwargs)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mself\u001b[39m._hook_progress({\u001b[33m'\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mstarted\u001b[39m\u001b[33m'\u001b[39m}, info_copy)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\postprocessor\\common.py:128\u001b[39m, in \u001b[36mPostProcessor._restrict_to.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, info)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allowed[format_type]:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\postprocessor\\ffmpeg.py:483\u001b[39m, in \u001b[36mFFmpegExtractAudioPP.run\u001b[39m\u001b[34m(self, information)\u001b[39m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [], information\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m filecodec = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_audio_codec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filecodec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\postprocessor\\ffmpeg.py:231\u001b[39m, in \u001b[36mFFmpegPostProcessor.get_audio_codec\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.probe_available \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.available:\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PostProcessingError(\u001b[33m'\u001b[39m\u001b[33mffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mPostProcessingError\u001b[39m: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mDownloadError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      7\u001b[39m save_dir=\u001b[33m\"\u001b[39m\u001b[33mdocs/youtube/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m loader = GenericLoader(\n\u001b[32m      9\u001b[39m     YoutubeAudioLoader([url],save_dir),  \u001b[38;5;66;03m# fetch from youtube\u001b[39;00m\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# FileSystemBlobLoader(save_dir, glob=\"*.m4a\"),   #fetch locally\u001b[39;00m\n\u001b[32m     11\u001b[39m     OpenAIWhisperParser()\n\u001b[32m     12\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m docs = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m docs[\u001b[32m0\u001b[39m].page_content[\u001b[32m0\u001b[39m:\u001b[32m500\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:43\u001b[39m, in \u001b[36mBaseLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m     38\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load data into `Document` objects.\u001b[39;00m\n\u001b[32m     39\u001b[39m \n\u001b[32m     40\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[33;03m        The documents.\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\langchain_community\\document_loaders\\generic.py:115\u001b[39m, in \u001b[36mGenericLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlazy_load\u001b[39m(\n\u001b[32m    112\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    113\u001b[39m ) -> Iterator[Document]:\n\u001b[32m    114\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load documents lazily. Use this when working at a large scale.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblob_loader\u001b[49m\u001b[43m.\u001b[49m\u001b[43myield_blobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblob_parser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlazy_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\langchain_community\\document_loaders\\blob_loaders\\youtube_audio.py:43\u001b[39m, in \u001b[36mYoutubeAudioLoader.yield_blobs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.urls:\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# Download file\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m yt_dlp.YoutubeDL(ydl_opts) \u001b[38;5;28;01mas\u001b[39;00m ydl:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m         \u001b[43mydl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Yield the written blobs\u001b[39;00m\n\u001b[32m     46\u001b[39m loader = FileSystemBlobLoader(\u001b[38;5;28mself\u001b[39m.save_dir, glob=\u001b[33m\"\u001b[39m\u001b[33m*.m4a\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3611\u001b[39m, in \u001b[36mYoutubeDL.download\u001b[39m\u001b[34m(self, url_list)\u001b[39m\n\u001b[32m   3608\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SameFileError(outtmpl)\n\u001b[32m   3610\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m url_list:\n\u001b[32m-> \u001b[39m\u001b[32m3611\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__download_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mextract_info\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3612\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_generic_extractor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mforce_generic_extractor\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3614\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._download_retcode\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3584\u001b[39m, in \u001b[36mYoutubeDL.__download_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   3581\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   3582\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m   3583\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3584\u001b[39m         res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3585\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m CookieLoadError:\n\u001b[32m   3586\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1634\u001b[39m, in \u001b[36mYoutubeDL.extract_info\u001b[39m\u001b[34m(self, url, download, ie_key, extra_info, process, force_generic_extractor)\u001b[39m\n\u001b[32m   1632\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ExistingVideoReached\n\u001b[32m   1633\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1634\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__extract_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_info_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1636\u001b[39m     extractors_restricted = \u001b[38;5;28mself\u001b[39m.params.get(\u001b[33m'\u001b[39m\u001b[33mallowed_extractors\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, [\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1645\u001b[39m, in \u001b[36mYoutubeDL._handle_extraction_exceptions.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1643\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1644\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1645\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1646\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (CookieLoadError, DownloadCancelled, LazyList.IndexError, PagedList.IndexError):\n\u001b[32m   1647\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1801\u001b[39m, in \u001b[36mYoutubeDL.__extract_info\u001b[39m\u001b[34m(self, url, ie, download, extra_info, process)\u001b[39m\n\u001b[32m   1799\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m process:\n\u001b[32m   1800\u001b[39m     \u001b[38;5;28mself\u001b[39m._wait_for_video(ie_result)\n\u001b[32m-> \u001b[39m\u001b[32m1801\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_ie_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mie_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1802\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1803\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ie_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1860\u001b[39m, in \u001b[36mYoutubeDL.process_ie_result\u001b[39m\u001b[34m(self, ie_result, download, extra_info)\u001b[39m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result_type == \u001b[33m'\u001b[39m\u001b[33mvideo\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_extra_info(ie_result, extra_info)\n\u001b[32m-> \u001b[39m\u001b[32m1860\u001b[39m     ie_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_video_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mie_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_pending_errors(ie_result)\n\u001b[32m   1862\u001b[39m     additional_urls = (ie_result \u001b[38;5;129;01mor\u001b[39;00m {}).get(\u001b[33m'\u001b[39m\u001b[33madditional_urls\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3038\u001b[39m, in \u001b[36mYoutubeDL.process_video_result\u001b[39m\u001b[34m(self, info_dict, download)\u001b[39m\n\u001b[32m   3036\u001b[39m downloaded_formats.append(new_info)\n\u001b[32m   3037\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3038\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3039\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MaxDownloadsReached:\n\u001b[32m   3040\u001b[39m     max_downloads_reached = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:187\u001b[39m, in \u001b[36m_catch_unsafe_extension_error.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _UnsafeExtensionError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    189\u001b[39m         \u001b[38;5;28mself\u001b[39m.report_error(\n\u001b[32m    190\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe extracted extension (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror.extension\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m) is unusual \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    191\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mand will be skipped for safety reasons. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    192\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mIf you believe this is an error\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbug_reports_message(\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3565\u001b[39m, in \u001b[36mYoutubeDL.process_info\u001b[39m\u001b[34m(self, info_dict)\u001b[39m\n\u001b[32m   3563\u001b[39m     replace_info_dict(\u001b[38;5;28mself\u001b[39m.post_process(dl_filename, info_dict, files_to_move))\n\u001b[32m   3564\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m PostProcessingError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m-> \u001b[39m\u001b[32m3565\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreport_error\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPostprocessing: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43merr\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3566\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   3567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1103\u001b[39m, in \u001b[36mYoutubeDL.report_error\u001b[39m\u001b[34m(self, message, *args, **kwargs)\u001b[39m\n\u001b[32m   1098\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreport_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, message, *args, **kwargs):\n\u001b[32m   1099\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1100\u001b[39m \u001b[33;03m    Do the same as trouble, but prefixes the message with 'ERROR:', colored\u001b[39;00m\n\u001b[32m   1101\u001b[39m \u001b[33;03m    in red if stderr is a tty file.\u001b[39;00m\n\u001b[32m   1102\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrouble\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_err\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mERROR:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mStyles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mERROR\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmessage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ebrady\\PersonalProjects\\gen-ai-app\\.venv\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1042\u001b[39m, in \u001b[36mYoutubeDL.trouble\u001b[39m\u001b[34m(self, message, tb, is_error)\u001b[39m\n\u001b[32m   1040\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1041\u001b[39m         exc_info = sys.exc_info()\n\u001b[32m-> \u001b[39m\u001b[32m1042\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DownloadError(message, exc_info)\n\u001b[32m   1043\u001b[39m \u001b[38;5;28mself\u001b[39m._download_retcode = \u001b[32m1\u001b[39m\n",
      "\u001b[31mDownloadError\u001b[39m: ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location"
     ]
    }
   ],
   "source": [
    "from langchain_classic.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.generic import FileSystemBlobLoader\n",
    "from langchain_classic.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain_classic.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "\n",
    "url=\"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "save_dir=\"docs/youtube/\"\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url],save_dir),  # fetch from youtube\n",
    "    # FileSystemBlobLoader(save_dir, glob=\"*.m4a\"),   #fetch locally\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "docs[0].page_content[0:500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2a97fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "handbook/titles-for-programmers.md at master · basecamp/handbook · GitHub\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Navigation Menu\n",
      "\n",
      "Toggle navigation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Sign in\n",
      "          \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Appearance settings\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PlatformAI CODE CREATIONGitHub CopilotWrite better code with AIGitHub SparkBuild and deploy intelligent appsGitHub ModelsManage and compare pro\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://github.com/basecamp/handbook/blob/master/titles-for-programmers.md\")\n",
    "\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "print(docs[0].page_content[:500])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8727287",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## Notion\n",
    "\n",
    "# Follow steps [here](https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/notion) for an example Notion site such as [this one](https://yolospace.notion.site/Blendle-s-Employee-Handbook-e31bff7da17346ee99f531087d8b133f):\n",
    "# \n",
    "# * Duplicate the page into your own Notion space and export as `Markdown / CSV`.\n",
    "# * Unzip it and save it as a folder that contains the markdown file for the Notion page.\n",
    "\n",
    "# ![image.png](./img/image.png)\n",
    "\n",
    "\n",
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "loader = NotionDirectoryLoader(\"docs/Notion_DB\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(docs[0].page_content[0:200])\n",
    "\n",
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95db0915",
   "metadata": {},
   "source": [
    "### Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9cbe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcdefghij', 'ghijklmnop', 'mnopqrstuv', 'stuvwxyz']\n",
      "['abcdefghij', 'ghijklmnop', 'mnopqrstuv', 'stuvwxyzab', 'yzabcdefg']\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "chunk_size = 10\n",
    "chunk_overlap = 4\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "\n",
    "text1 = 'abcdefghijklmnopqrstuvwxyz'\n",
    "print(r_splitter.split_text(text1))\n",
    "\n",
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\n",
    "print(r_splitter.split_text(text2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcd460f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a b c d e', 'd e f g h', 'g h i j k', 'j k l m n', 'm n o p q', 'p q r s t', 's t u v w', 'v w x y z']\n",
      "['a b c d e f g h i j k l m n o p q r s t u v w x y z']\n",
      "['a b c d e', 'd e f g h', 'g h i j k', 'j k l m n', 'm n o p q', 'p q r s t', 's t u v w', 'v w x y z']\n"
     ]
    }
   ],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "\n",
    "print(r_splitter.split_text(text3))\n",
    "\n",
    "print(c_splitter.split_text(text3))\n",
    "\n",
    "c_splitter = CharacterTextSplitter( # default splitter with /n\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator = ' '\n",
    ")\n",
    "print(c_splitter.split_text(text3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58474280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is',\n",
       " 'is weird',\n",
       " '. I like',\n",
       " 'plants',\n",
       " '. The',\n",
       " 'The quick',\n",
       " 'brown fox',\n",
       " 'fox jumps',\n",
       " 'over the',\n",
       " 'the lazy',\n",
       " 'dog.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try your own examples!\n",
    "# `RecursiveCharacterTextSplitter` is recommended for generic text. \n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separators=[\". \", \" \"]\n",
    ")\n",
    "\n",
    "text1 = 'This is weird. I like plants. The quick brown fox jumps over the lazy dog.'\n",
    "r_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1561a293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,', 'have a space.and words are separated by space.']\n",
      "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\", 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']\n"
     ]
    }
   ],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\"\n",
    "\n",
    "\n",
    "len(some_text)\n",
    "\n",
    "\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"] \n",
    "    # works left to right. First split by \\n\\n. IF still need to split, then \\n, then space, then empty\n",
    ")\n",
    "\n",
    "\n",
    "print(c_splitter.split_text(some_text))\n",
    "\n",
    "\n",
    "print(r_splitter.split_text(some_text)) # even though splits before 450 chars, splits at new paragraph which is more relevant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac73a25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related\",\n",
       " '. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns',\n",
       " '. Carriage returns are the \"backslash n\" you see embedded in this string',\n",
       " '. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's reduce the chunk size a bit and add a period to our separators:\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646079ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\ebrady\\AppData\\Local\\Temp\\ipykernel_22600\\2116330749.py:4: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de348cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"docs/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "\n",
    "from langchain_classic.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "len(docs)\n",
    "len(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1be82b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', ' bar', ' b', 'az', 'zy', 'foo']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ## Token splitting\n",
    "\n",
    "# We can also split on token count explicity, if we want.\n",
    "# This can be useful because LLMs often have context windows designated in tokens.\n",
    "# Tokens are often ~4 characters.\n",
    "\n",
    "from langchain_classic.text_splitter import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)\n",
    "text1 = \"foo bar bazzyfoo\"\n",
    "text_splitter.split_text(text1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "28ce68a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='MachineLearning-Lecture01  \n",
      "' metadata={'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2008-07-11T11:25:23-07:00', 'author': '', 'moddate': '2008-07-11T11:25:23-07:00', 'title': '', 'source': 'docs/MachineLearning-Lecture01.pdf', 'total_pages': 22, 'page': 0, 'page_label': '1'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'producer': 'Acrobat Distiller 8.1.0 (Windows)',\n",
       " 'creator': 'PScript5.dll Version 5.2.2',\n",
       " 'creationdate': '2008-07-11T11:25:23-07:00',\n",
       " 'author': '',\n",
       " 'moddate': '2008-07-11T11:25:23-07:00',\n",
       " 'title': '',\n",
       " 'source': 'docs/MachineLearning-Lecture01.pdf',\n",
       " 'total_pages': 22,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "print(docs[0])\n",
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fb847364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1481"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1ae0013a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'}, page_content='Hi this is Lance')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Context aware splitting\n",
    "\n",
    "# Chunking aims to keep text with common context together.\n",
    "# A text splitting often uses sentences or other delimiters to keep related text together but many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting.\n",
    "# We can use `MarkdownHeaderTextSplitter` to preserve header metadata in our chunks, as show below.\n",
    "\n",
    "from langchain_classic.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)\n",
    "\n",
    "md_header_splits[0]\n",
    "md_header_splits[1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
